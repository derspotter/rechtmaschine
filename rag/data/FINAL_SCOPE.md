# RAG System - Final Ingestion Scope

**Analysis Date:** 2025-10-31
**Corpus:** `/run/media/jayjag/My Book1/RAG/kanzlei/`

---

## âœ… What Gets Ingested

**~3,122 documents** consisting of:
- **Kanzlei Keienborg legal briefs** (SchriftsÃ¤tze, Klagen, Beschwerden)
- **Date-prefixed court filings** (e.g., `251013_vg_klage.odt`)
- **Case-specific legal documents**

### Document Types:
- 51.0% - SchriftsÃ¤tze (court filings)
- 20.5% - Klagen (lawsuits)
- 17.8% - Other dated documents
-  9.2% - Other legal docs
-  1.0% - BAMF filings
-  0.3% - Beschwerden (appeals)

### File Formats:
- 1,718 PDFs
- 1,404 ODTs (will be converted to PDF)

---

## âŒ What Gets Excluded

**~7,227 documents** excluded:
- ~3,122 - Buchhaltung folders (accounting/billing)
- ~3,122 - 00 AT folder (templates, admin)
- ~703 - Vollmacht files (power of attorney)
- ~703 - PKH/Mittellosigkeit (legal aid applications)
- ~3,402 - External documents (BAMF decisions, court rulings without letterhead)

---

## ğŸ”§ Pipeline Configuration

### 1. **Document Filtering**
```python
INCLUDE:
âœ“ Has "Kanzlei Keienborg" letterhead
âœ“ Located in case folders (23/*, 24/*, 25/*)

EXCLUDE:
âœ— buchhaltung/* folders
âœ— 00 AT/* folder
âœ— *vollmacht* files
âœ— *pkh* / *pka* / *mittellos* files
âœ— No letterhead (external docs)
```

### 2. **Processing Steps**

```
Step 1: ODTâ†’PDF Conversion (LibreOffice)
â”œâ”€ Input:  1,404 ODT files
â”œâ”€ Tool:   soffice --headless --convert-to pdf
â””â”€ Time:   ~46 minutes

Step 2: PDF Parsing (Hybrid)
â”œâ”€ Primary:  PyMuPDF (fast, 70% success)
â”œâ”€ Fallback: Docling (OCR for scanned docs, 30%)
â”œâ”€ Input:    ~3,122 PDFs
â””â”€ Time:     ~26 minutes

Step 3: Anonymization (REQUIRED)
â”œâ”€ Service: http://localhost:8004/anonymize
â”œâ”€ Backend: Qwen3-14B via Ollama (port 9002)
â”œâ”€ Purpose: Remove client names, case-specific details
â”œâ”€ Note:    Even Kanzlei docs may contain personal info
â””â”€ Time:    ~156 minutes (longest step)

Step 4: Section Classification
â”œâ”€ Patterns: German legal structure
â”‚   â€¢ I., II., III. (numbered sections)
â”‚   â€¢ "Zur Lage in..." (country conditions)
â”‚   â€¢ "Rechtliche WÃ¼rdigung" (legal reasoning)
â”‚   â€¢ "Sachverhalt" (facts)
â”œâ”€ Types: country_conditions, legal_argument,
â”‚         medical_risk, procedural_background
â””â”€ Time:  ~10 minutes

Step 5: Deduplication (Hash-based)
â”œâ”€ Strategy: SHA-256 hash of normalized text
â”œâ”€ Scope:    Legal sections (not personal facts)
â”œâ”€ Expected: 60-80% deduplication rate
â”‚   â€¢ Country conditions blocks highly reused
â”‚   â€¢ Legal reasoning templates common
â”‚   â€¢ Medical risk arguments (PTSD) repeated
â””â”€ Time:  ~15 minutes

Step 6: Chunking
â”œâ”€ Size:    400-500 tokens per chunk
â”œâ”€ Overlap: 100 tokens between chunks
â”œâ”€ Total:   ~31,220 chunks (before dedup)
â”œâ”€ Unique:  ~9,366 chunks (after dedup)
â””â”€ Time:    ~26 minutes

Step 7: Embedding (GPU)
â”œâ”€ Model:   Qwen3-Embedding-4B
â”œâ”€ Device:  CUDA (RTX 3060 12GB VRAM)
â”œâ”€ Dim:     1024 (reduced from 2560)
â”œâ”€ Batch:   8 chunks per batch
â””â”€ Time:    ~104 minutes

Step 8: Vector Database Storage
â”œâ”€ DB:      PostgreSQL + pgvector
â”œâ”€ Index:   HNSW or IVFFlat
â”œâ”€ Columns: id, text, metadata (JSONB), embedding (vector(1024))
â””â”€ Time:    ~10 minutes

Total Pipeline Time: ~6 hours
```

### 3. **Storage Estimates**

```
Vector Database (PostgreSQL + pgvector):
â”œâ”€ Chunks:              ~9,366 unique
â”œâ”€ Vector storage:      ~37 MB (1024-dim float32)
â”œâ”€ Text storage:        ~4 MB
â”œâ”€ Metadata (JSONB):    ~5 MB
â””â”€ Total:               ~46 MB (very reasonable!)

Deduplication Savings:
â”œâ”€ Before dedup:  31,220 chunks â†’ ~122 MB
â”œâ”€ After dedup:    9,366 chunks â†’ ~37 MB
â””â”€ Savings:        70% reduction (21,854 chunks eliminated)
```

### 4. **Metadata Fields**

Each chunk will have:

```json
{
  "chunk_id": "uuid",
  "source_file": "24/014 NOUR vs BRD/251013_vg_klage.pdf",
  "source_type": "odt",
  "doc_date": "2025-10-13",
  "court": "vg",
  "doc_type": "klage",
  "section_type": "legal_argument",
  "case_folder": "24/014 NOUR vs BRD",
  "anonymized": true,
  "anonymizer_version": "v1.0",
  "embedding_model": "Qwen3-Embedding-4B-dim1024",
  "canonical_hash": "sha256:...",
  "created_at": "2025-10-31T..."
}
```

---

## ğŸ¯ Key Optimizations

### 1. **No External Documents**
- Only ingest your own legal work
- Excludes BAMF decisions, court rulings
- Focused corpus = better retrieval quality

### 2. **Smart Exclusions**
- Skip accounting docs (irrelevant)
- Skip templates (redundant with actual briefs)
- Skip Vollmacht (boilerplate)
- Skip PKH (administrative)

### 3. **High Deduplication**
- Legal arguments are templated
- Country condition sections reused extensively
- 70% deduplication rate = massive storage savings

### 4. **Anonymization Required**
- Even your own briefs may contain:
  - Client names (if not carefully written)
  - Case-specific dates/locations
  - Identifying details
- Better safe than sorry for GDPR compliance

---

## ğŸ“Š Example Documents

Sample ingested documents:
```
24/003 ALI vs BRD/240108_ag_beschwerde.odt
24/007 FARAZANEH vs BRD/240110_vg_klage_80v.odt
24/014 NOUR vs BRD/251013_vg_klage.odt
24/021 ALBUAWADH vs BRD/240205_vg_ae.odt
25/015 NAME vs BRD/250315_ovg_beschwerde.odt
```

Naming convention:
```
YYMMDD_court_doctype.odt
  â†“      â†“       â†“
 Date   VG/OVG  klage/schriftsatz/beschwerde
```

---

## ğŸš€ Next Implementation Steps

1. **Create requirements.txt** âœ“ (partially done)
2. **Implement ODT converter** (LibreOffice subprocess)
3. **Implement hybrid PDF parser** (PyMuPDF + Docling)
4. **Implement letterhead filter** (exclude non-Kanzlei docs)
5. **Integrate anonymization** (service_manager.py client)
6. **Implement section classifier** (regex + heuristics)
7. **Implement deduplicator** (SHA-256 hash)
8. **Implement chunker** (tiktoken-based)
9. **Set up PostgreSQL + pgvector**
10. **Implement embedder** (Qwen3-Embedding-4B on GPU)
11. **Create ingestion orchestrator**
12. **Build retrieval API**
13. **Test with sample documents**

---

## âœ… Validation Checks

Before production deployment:

- [ ] Anonymization removes all client names
- [ ] No documents from buchhaltung/ ingested
- [ ] No documents from 00 AT/ ingested
- [ ] No Vollmacht files ingested
- [ ] No PKH files ingested
- [ ] All ingested docs have Kanzlei letterhead
- [ ] Deduplication working (check hash collisions)
- [ ] Vector search returns relevant results
- [ ] Metadata extraction accurate (dates, courts, types)
- [ ] Database size within expectations (~50 MB)

---

## ğŸ“ Notes

- **Privacy:** All documents anonymized before embedding
- **GDPR:** No client names/PII in vector database
- **Performance:** GPU embedding on RTX 3060 (12GB VRAM)
- **Scalability:** System designed for ~3,000-5,000 documents
- **Future growth:** Can re-index if embedding model changes
